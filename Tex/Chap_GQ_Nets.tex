\chapter{量化网络的反向蒸馏训练} \label{chap::gq_nets}

% ==============================================================================
%  Introduction
% ==============================================================================
\section{引言}
第~\ref{chap::fqn} 章针对 FQN 模型的分析显示，基于量化神经网络的目标检测模型训练较一般模型困难，其原因在于量化误差为目标检测模型训练引入了更多不稳定性。若针对此类误差建模，并在训练过程中显式地优化该误差，则有可能得到更为鲁棒的量化目标检测模型。

本章介绍一种将神经网络量化误差以可微分形式隐式建模，并利用类似模型蒸馏训练的反向蒸馏技术，将该误差模型引入原网络训练过程的训练方法。该方法可平行整合至原模型训练方法中，将模型训练过程引导至同时最小化原损失函数和量化误差的求解点，从而得到适合被量化运行的神经网络模型。我们称使用该方法训练的量化神经网络为 GQ-Nets (Guided Quantization Networks)。

GQ-Nets 使用在相同输入下，量化神经网络和全精度浮点神经网络之间最终输出的不一致性作为量化误差的度量。在分类任务中，该不一致性由各神经网络最后一层输出（即 logits）间的 KL--散度刻画；在检测任务中，则由模型分类子网络输出的 logits 间的 KL--散度，以及回归子网络输出间的 smooth L1-loss \unsure{也许应该使用 L2-loss？} 一同刻画。这类一致性标准虽然没有针对模型参数及量化参数的显式表达式，但通过在量化操作的反向传播过程中引入 STE，其计算过程变得可微分，从而使得量化误差能够在训练过程中被显式地优化。

在将针对量化误差的优化引入原模型训练过程后，原模型优化问题演化为一阶多目标优化问题，即需要考虑最小化量化误差的梯度是否会与原模型训练梯度冲突。通过在模型训练过程中对这两组梯度间余弦相似度的度量，揭示了这两组梯度在训练的多数过程中近似正交；即对于大部分任务而言，减少模型量化误差这一任务并不与模型原始任务冲突。基于上述观察，本章引入了调和这两组梯度的一系列训练方法，并对其效果进行了分析比较。
% ------------------------------------------------------------------------------
%    Motivation
% ------------------------------------------------------------------------------
\subsection{工作动机}

\paragraph{对量化误差的端到端建模}
之前工作对神经网络量化过程的误差建模多集中在逐层或逐张量误差分析，以及依赖特定显式一致性指标，例如（……）。然而，在较为复杂的神经网络中，这可能导致两方面的问题：
\begin{enumerate}[1)]
  \item 逐层或逐张量误差分析可能不够准确：例如在 MobileNet 系列模型中，由于层参数量较少导致各卷积核表达能力受限，使用 depth-wise convolution 的中间层会产生较大的参数量化误差和激活量化误差，然而模型最终的误差却仍可能被控制在较小范围内（……）；
  \item 使用某一特定的显式一致性指标不一定能适应各种任务：例如在目标检测的回归子网络中，其输出的一致性指标一般用 L2-loss 或 smooth L1-loss 刻画；在嵌入向量的非监督学习中，则一般用余弦相似度刻画嵌入向量间的一致性；
\end{enumerate}
因此我们提出，应针对所用神经网络模型的任务使用相应的一致性指标，并以\emph{相同输入}下，全精度模型和量化模型\emph{最终输出}间的一致性，作为量化误差的衡量标准。也就是说，相较于模型训练或推理时某些中间层的局部误差，我们更关注模型最终输出间的不匹配度。

\paragraph{在模型预训练阶段即引入量化误差}
之前基于量化感知训练的工作，一般采取“预训练——量化感知微调”的两段式训练方法来减少神经网络的量化误差。然而，这类训练流程的代价是训练时间消耗几乎是传统训练的 $2\times$ 以上，且在量化感知微调阶段需要模型的完整训练数据集。例如在 LIQ 的 ImageNet 分类任务上，模型先在预训练阶段训练 120 轮，之后再在量化感知微调阶段训练 $60\sim 90$ 轮。如果考虑在量化感知微调阶段，模型计算图中包含的更多额外操作（例如量化、反量化、量化 STE 算子的梯度修改等），则在 ImageNet 分类任务上 LIQ 的总训练时长约是一般全精度模型的 $2\times$ 左右。与此同时，在实际应用场景中，模型在量化部署前一般很难接触到完整的训练数据集（例如模型的设计、训练和部署分别由不同的技术团队负责，各团队间数据不一定共享），这直接导致了两段式量化感知训练在实际场景中不一定可行。因此在 GQ-Nets 在能够接触完整训练数据的模型预训练阶段，即开始考虑模型量化运行的误差，并直接在模型参数优化时，尽可能消除该误差。

\paragraph{调和训练阶段多任务梯度}
对于较复杂的神经网络模型而言，其训练过程已包含来自不同任务损失函数的梯度——例如在用于实例分割的 Mask R-CNN 训练过程中，模型参数同时被最小化分类损失、检测锚框回归损失和分割掩模的三组梯度更新。在 GQ-Nets 的训练过程中，最小化量化误差会为模型参数生成另一组梯度。使用多组随训练过程频繁变化的梯度，优化同一组模型参数是较为困难的。因此，GQ-Nets 提出的在预训练阶段减小量化误差的挑战之一是，调和各损失函数的对应梯度，使模型能够收敛至同时最小化所有损失函数的解。
% ------------------------------------------------------------------------------
%    Contributions
% ------------------------------------------------------------------------------
\subsection{主要贡献}
\begin{enumerate}[1.]
  \item 本章提出了 GQ-Nets，一种使用量化神经网络与全精度神经网络间端到端不匹配度作为量化误差建模，并将该误差引入模型预训练阶段，从而直接得到量化友好的神经网络模型的训练方法；
  \item 本章深入分析了 GQ-Nets 在训练阶段的诸多特性，提出并验证了调和多任务训练不同梯度的多个方法；
  \item 本章在不同任务和大量真实数据集上验证了 GQ-Nets 的有效性，包括在 CIFAR、ImageNet 数据集上的图片分类任务，以及在 MS~COCO \improvement{在 mmdetectin 上补实验} 数据集上的多类别目标检测任务。
\end{enumerate}

% ==============================================================================
%  Modeling Quantization Errors
% ==============================================================================
\section{量化误差的建模} \label{sec::gq_nets::q_error}

\begin{figure}[htb]
  \centering
  \includegraphics[width=\columnwidth]{GQ_Nets/arch.pdf}
  \caption{GQ-Nets 的主要结构。其中，……}
  \label{img::gq_nets::arch}
\end{figure}

为了能在预训练阶段减小神经网络模型的量化误差，GQ-Nets 将神经网络模型的量化误差构造为：在初始全精度神经网络模型的基础上，使用同一套模型参数\emph{并行地}构建一个量化神经网络模型，将它们在同一输入下的最终输出与全精度模型的对应输出相类比，作为量化误差的衡量指标。GQ-Nets 的主要结构如图~\ref{img::gq_nets::arch} 所示，其中的前向传播（forward pass）部分展示了在预训练阶段对量化误差 $\mathcal{L}_f$ 及模型整体损失函数 $\mathcal{L}$ 的构造，反向传播（backward pass）部分展示了采用整体损失函数 $\mathcal{L}$ 对模型参数做量化感知训练的细节。本节先详细讨论前向传播过程中模型量化误差的构造方式，第~\ref{sec::gq_nets::train} 节讨论该框架的具体优化细节。

在前向传播过程中，GQ-Nets 各部分及其运行流程如下：
\begin{enumerate}[1.]
  \item 初始 $L$ 层全精度神经网络模型 $f_{\mathcal{W}}$，其中 $\mathcal{W} = \{W_1, \ldots, W_L\}$ 表示模型的权重参数（下文统称为\emph{权重参数}），而 $W_i, i \in 1 \ldots L$ 分别表示模型第 $i$ 层的权重参数，均以浮点形式存储及运算；
  \item 由 $f_{\mathcal{W}}$ 构建而来的 $L$ 层量化神经网络模型 $\hat{f}_{\mathcal{W}, \mathcal{Q}}$，其中 $\mathcal{Q}$ 表示量化模型在运行时所用的量化函数。 具体地，$\mathcal{Q} = \{Q^w_1, \ldots , Q^w_L, Q^a_1, \ldots , Q^a_L\}$ ，其中 $Q^w_i, i \in 1\ldots L$ 表示用于量化第 $i$ 层权重参数的量化函数，$Q^a_i, i \in 1\ldots L$ 表示用于量化第 $i$ 层模型激活的量化函数。注意在 GQ-Nets 中，每一个量化函数都分别被一组参数 $\theta^w_i$ （用于参数量化函数 $Q^w_i$ ）或 $\theta^a_i$ （用于激活量化函数 $Q^a_i$ ）参数化。每组参数 $\theta = \{k, lb, ub\}$ ，\footnote{此处省略 $\theta$ 上下标。}包括量化比特位宽 $k \in \mathbb{Z}^+$，量化截断上下界 $ub, lb \in \mathbb{R}$，其中 $ub, lb$ 是可学习参数。下文统称 $\Theta = \{\theta^w_1, \ldots , \theta^w_L, \theta^a_1, \ldots , \theta^a_L\}$ 为\emph{量化参数}。本章中所有参数化量化函数 $Q$ 均使用带截断的线性量化，即给定一输入向量 $x$ （可以是模型参数、输入或中间激活）和量化参数 $\theta = \{k, lb, ub\}$，其对应量化输出 $\hat{x}$ 为
  \begin{align}
    \Delta &= \frac{ub - lb}{2^k - 1} \\
    \hat{x} &= Q(x; k, lb, ub) \notag \\
            &= \Delta \lfloor \frac{\mathrm{clip}(x, lb, ub) - lb}{\Delta} \rceil + lb
  \end{align}
  其中 $\mathrm{clip}(x, lb, ub) = \max(lb, \min(x, ub))$ 为截断操作符，在实际量化前将 $x$ 所有数值范围控制在 $[lb, ub]$ 范围内；$\lfloor\cdot\rceil: \mathbb{R}\to\mathbb{Z}$ 为舍入操作符。注意 $\hat{f}_{\mathcal{W}, \mathcal{Q}}$ 通过权重参数量化函数 $Q^w_{1\ldots L}$，与 $f_{\mathcal{W}}$ 共享一套权重参数 $\mathcal{W}$；
  \item GQ-Nets 模型各层在前向传播时，同时计算浮点和量化的中间激活值。具体地，在得到一经过预处理的、以浮点格式存储的小批量输入 $x_0$ 后，第 $i=1$ 层首先计算该层的浮点输出激活 $x_1 = x_0 \star_1 W_1$，其中 $\star_1$ 表示该层的对应操作（例如卷积、逐通道分离卷积或池化等）；之后将该层的输入 $x_0$、权重参数 $W_1$ 使用对应的量化函数及量化参数进行量化 $\hat{x}_0 = Q^a_1(x_0; \theta^a_1), \hat{W}_1 = Q^w_1(W_1; \theta^w_1)$，即可计算得到该层的量化输出激活 $\tilde{x}_1 = \hat{x}_0 \star_1 \hat{W}_1$。对于 $i\in 2\ldots L$ 层，浮点和量化前向计算不再共享输入，即分别使用 $i-1$ 层的浮点输出激活 $x_{i-1}$ 和量化输出激活 $\tilde{x}_{i-1}$ 计算本层的浮点输出 $x_i = x_{i-1} \star_i W_i$ 和量化输出 $\tilde{x}_i = Q^a_i(\tilde{x}_{i-1}; \theta^a_i) \star_i Q^w_i({W}_{i}; \theta^w_i)$ 。注意各层在执行量化前向计算时，由于其输入和权重参数均已被量化，故 $\tilde{x}_i$ 可完全由定点或整数数值逻辑计算得出；
  \item 在得到第 $L$ 层的浮点输出 $x_L$ 和量化输出 $\tilde{x}_L$ 后，分别计算反映模型在目标任务上准确度的原损失函数 $\mathcal{L}_f$ 及反映模型量化输出与浮点输出间相似程度的量化误差度量 $\mathcal{L}_q$，并由此计算模型训练的总体损失函数 $\mathcal{L}$。不失一般性地，本章中使用线性加权计算 $\mathcal{L}$，即
  \begin{align}
    \mathcal{L} = w_f \mathcal{L}_f + w_q \mathcal{L}_q \label{eq::gq_nets::total_loss}
  \end{align}
  其中 $w_f, w_q \in \mathbb{R}$ 分别表示模型训练过程对准确度和量化误差减少的偏重程度，并可以在训练过程中动态调整。对于分类任务，$\mathcal{L}_f$ 一般表示为模型最终浮点输出 $x_L$ 对应的概率分布与当前小批量输入标签 $y$ 间的交叉熵 $\mathcal{L}_f = \CE{\sigma(x_L)}{y}$，而 $\mathcal{L}_q$ 则表示为模型量化输出对应的概率分布相较于浮点输出对应的概率分布间的 KL--散度 $\mathcal{L}_q = \KL{\sigma(\tilde{x}_L)}{\sigma(x_L)}$，其中 $\sigma(\cdot)$ 表示 softmax 操作。对于回归任务（例如目标检测中检测框坐标尺寸），$\mathcal{L}_f$ 一般表示为回归子网络输出与检测框标定间的 smooth L1-loss ， $\mathcal{L}_q$ 一般表示为全精度和量化回归子网络输出间的 L2-loss 。
  
  通过构造损失函数~\eqref{eq::gq_nets::total_loss} 的第二项，GQ-Nets 在模型预训练阶段即可刻画出当前模型的量化误差。在此误差的构造过程中，我们只关注量化模型\emph{最终}输出与全精度输出的近似性，为模型保留了更多优化空间。\ref{sec::gq_nets::train} 节将详细讨论针对该误差模型的优化方法。
\end{enumerate}

% ==============================================================================
%  Method
% ==============================================================================
\section{反向蒸馏训练} \label{sec::gq_nets::train}
\improvement{在这里详细说明为什么叫“反向蒸馏”训练}
GQ-Nets 在预训练阶段构造模型量化误差~\eqref{eq::gq_nets::total_loss} 中 $\mathcal{L}_q$ 时，前向传播运算的几乎所有操作算子均可微分，并且模型的所有权重参数 $\mathcal{W}$ 及量化参数 $\Theta$ 均参与了构造。因此，以适当的优化方法最小化~\eqref{eq::gq_nets::total_loss} 即可以得到一套量化友好的模型权重 $\mathcal{W}$ 及与之对应的量化运行时参数 $\Theta$。使用基于梯度的方法优化~\eqref{eq::gq_nets::total_loss} 需要考虑以下问题：
\begin{enumerate}[1)]
  \item 在训练过程中权衡 $\mathcal{L}_f$ 与 $\mathcal{L}_q$ 间的重要性，防止两者梯度在训练时互相冲突，或训练由某一组梯度完全主导，以确保训练方法能得到在目标任务上足够准确、同时量化后额外误差最小的模型；
  \item 量化模型 $\hat{f}_{\mathcal{W, Q}}$ 计算图在反向传播时的额外细节，例如 $\lfloor\cdot\rceil$ 操作默认不可微分、针对 $\mathcal{L}_q$ 的优化可能降低 $f_{\mathcal{W}}$ 的准确度等；
  \item 浮点和量化模型在训练过程中，其激活分布可能会不一致，需要使用相应的方法分别做正则化处理。
\end{enumerate}
本节讨论针对上述问题的一系列解决方案，使 GQ-Nets 可以在不显著修改原模型 $f_{\mathcal{W}}$ 的基础上，训练得到高准确度且无需额外微调的量化友好模型 $f_{\mathcal{W, Q}}$。
% ------------------------------------------------------------------------------
%    Loss function
% ------------------------------------------------------------------------------
\subsection{损失函数设计}
正如在第~\ref{sec::gq_nets::q_error} 节所讨论的，GQ-Nets 损失函数~\eqref{eq::gq_nets::total_loss} 的构造思路是，通过优化原模型损失函数 $\mathcal{L}_f$ 使模型在目标任务上保持高准确度，同时优化量化误差项 $\mathcal{L}_q$ 使模型在量化后不产生明显的输出误差。然而需要注意的是，直接优化 $\mathcal{L}_q$ 会使 $x_L$ 和 $\tilde{x}_L$ 趋向一致，这一过程可能会使浮点输出对应的概率分布 $\sigma(x_L)$ 偏离目标分布 $y$，从而与 $\mathcal{L}_f$ 的优化冲突。

为解决此问题，GQ-Nets 在构造 $\mathcal{L}_q$ 时，将浮点输出对应的概率分布 $\sigma(x_L)$ 看作\emph{常数项}，从而其梯度 $\nabla_{\mathcal{W}, \Theta} \mathcal{L}_q$ 只会通过量化模型的输出 $\tilde{x}_L$ 作用于 $\hat{f}_{\mathcal{W, Q}}$，使量化模型输出对应概率 $\sigma(\tilde{x}_L)$ 趋近于 $\sigma(x_L)$，而不会对 $\sigma(x_L)$ 的准确度产生负面影响。虽然 $\nabla_{\mathcal{W}, \Theta} \mathcal{L}_q$ 最终仍会作用到模型权重参数 $\mathcal{W}$ 上，但上述操作解藕了 $f_{\mathcal{W}}$ 和 $\hat{f}_{\mathcal{W, Q}}$ 的优化。如图~\ref{img::gq_nets::detach_grad_cos} 所示，解藕后 $\nabla_{\mathcal{W}} \mathcal{L}_f$ 和 $\nabla_{\mathcal{W}} \mathcal{L}_f$ 在训练过程中基本保持正交，使模型整体训练更快收敛，且最终产生更准确的模型。

\begin{figure}[htb]
  \centering
  \missingfigure[figwidth=0.9\columnwidth]{\normalsize 脱离梯度前后，最后一层参数收到的梯度间的余弦夹角}
  \caption{TODO: 脱离梯度前后，最后一层参数收到的梯度间的余弦夹角}
  \label{img::gq_nets::detach_grad_cos}
\end{figure}

上述操作反映到图~\ref{img::gq_nets::arch} 中，即 $\mathcal{L}_q$ 在反向传播过程中，其梯度（对应橙色箭头）仅指向量化输出 $\tilde{x}_L$，而不直接影响 $x_L$。这一操作可以在 PyTorch 中使用 \texttt{detach} 操作符，或在 TensorFlow 中使用 \texttt{stop\_gradient} 操作符实现。其数学定义为
\begin{align}
  \NoDiff{x} =
    \begin{cases}
      x & \text{forward} \\
      0 & \text{backward}
    \end{cases}
\end{align}
在执行上述操作后，\eqref{eq::gq_nets::total_loss} 中 $\mathcal{L}_q$ 项应改写为
\begin{align}
  \mathcal{L}_q = \KL{\sigma(\tilde{x}_L)}{\sigma(\NoDiff{x_L})}
\end{align}
% ------------------------------------------------------------------------------
%    Optimization
% ------------------------------------------------------------------------------
\subsection{损失函数优化}
除量化误差建模及整体损失函数构造外，使用~\eqref{eq::gq_nets::total_loss} 生成的梯度优化模型参数 $\{\mathcal{W}, \Theta\}$ 还需要解决两个问题：$\hat{f}_{\mathcal{W, Q}}$ 计算图反向传播时，不可微分算子及其他特殊算子需做相应处理处理；以及模型训练时对 $\mathcal{L}_f$ 和 $\mathcal{L}_q$ 的侧重程度。

在反向传播时，GQ-Nets 使用 STE 直接将梯度“跳过”计算图中的 $\Round{\cdot}$ 等不可微分操作，即
\begin{align}
  \diff{y}{\Round{x}} \diff{\Round{x}}{x} &= \diff{y}{\Round{x}}
\end{align}
反向传播时的另一类特殊算子，是量化模型 $\hat{f}_{\mathcal{W, Q}}$ 中保留为浮点运行的部分，例如模型的第一层、最后一层等。\footnote{保留浮点操作的量化模型对于实际硬件部署并不友好，讨论此情形主要便于对比其他工作。} 这类层在量化训练时应视为对其量化输入的参数化变换，故其权重参数 $W_i$ 在更新时应只接受由原模型损失函数所传回的梯度 $w_f \nabla_{W_i}\mathcal{L}_f$，而不叠加量化误差函数传回的梯度 $w_q \nabla_{W_i}\mathcal{L}_q$。\improvement{仔细说清楚为什么只接受 $\mathcal{L}_f$ 的梯度}

在 GQ-Nets 训练的不同阶段，损失函数~\eqref{eq::gq_nets::total_loss} 中权重项 $w_f$ 和 $w_q$ 刻画了训练过程中 $\mathcal{L}_f$ 和 $\mathcal{L}_q$ 的相对重要程度。较大的 $w_f$ 会增大由全精度模型损失函数 $\mathcal{L}_f$ 生成的梯度幅度，从而得到准确度较高，却很可能不够量化友好的模型。与之相对，较大的 $w_q$ 会得到量化友好的模型，而其准确度却有可能降低。本章探讨了多种在训练过程中权衡 $w_f$ 和 $w_q$ 的方法。

首先，我们发现用最简单的等值常数权重，即在整个训练过程中 $w_f = w_q = 0.5$ 就可得到优于很多先前方法的结果（见~\ref{sec::gq_nets::exp} 节实验结果）。这可能是因为，由 GQ-Nets 损失函数~\eqref{eq::gq_nets::total_loss} 生成的两组梯度 $w_f \nabla_{\mathcal{W}}\mathcal{L}_f$ 和 $w_q \nabla_{\mathcal{W}, \Theta}\mathcal{L}_q$ 链式传播到 $\mathcal{W}$ 后基本正交而不会相互冲突（见图~\ref{img::gq_nets::detach_grad_cos}）。

其次，我们根据实验发现，在训练过程中动态地调整 $w_f$ 和 $w_q$ 能得到准确度更高的量化模型。其中一种调节策略如图~\ref{img::gq_nets::w_schedule} 所示，

\begin{figure}[htb]
  \centering
  \includegraphics[width=0.7\columnwidth]{GQ_Nets/schedule.pdf}
  \caption{在训练不同阶段动态调整模型全精度损失项权重 $w_f$ 和量化误差项权重 $w_q$ 的一种策略。在模型训练初始阶段，以及每次学习率下降之后，先不优化量化误差项，之后再缓慢线性增加。}
  \label{img::gq_nets::w_schedule}
\end{figure}
% ------------------------------------------------------------------------------
%    Multi-domain BN
% ------------------------------------------------------------------------------
\subsection{多域批量正则化}
TODO

% ==============================================================================
%  Experiments
% ==============================================================================
\section{主要实验结果} \label{sec::gq_nets::exp}
TODO

% ==============================================================================
%  Ablation study
% ==============================================================================
\section{对比实验及分析}
TODO

% ==============================================================================
%  Conclusion
% ==============================================================================
\section{结论}
TODO

