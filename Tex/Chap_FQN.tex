\chapter{用于目标检测的全量化网络} \label{chap::fqn}
% ==============================================================================
%  Introduction
% ==============================================================================
\section{引言}
正如第~\ref{chap::background} 章所介绍，基于深度学习的目标检测技术已在大量真实世界的任务上取得显著成功（……）。然而，高昂的运算和存储开销，是将目标检测技术广泛应用到诸如智能手机、智能安防相机、自动驾驶系统等计算资源受限场景的主要障碍。为减少深度学习模型的运算和存储开销，近年来学术界和工业界探索了多种解决路径，其中主要方向包括高效的模型算子和结构探索（MobileNet, ShuffleNet, SqueezeNet, etc.）、以部署平台模型推理时间为约束的模型结构自动搜索（FBNet, Han group works, ……）、模型剪枝（The Lottery Ticket Theory, etc.）和模型量化等。其中，模型量化技术由于可以显著减少模型尺寸，同时使用更高效的整数或定点运算逻辑代替一般深度学习模型所需的浮点运算逻辑而提高推理效率，近年来受到了较多关注，也是本章讨论的重点。

现有的模型量化技术在物体分类等相对简单的任务上表现出色（……），然而将其应用到目标检测这一较为复杂的任务时，会在模型训练及硬件部署时面临额外的挑战：
\begin{enumerate}[1)]
  \item 与只需学习模型输出间偏序关系的分类任务不同，目标检测还额外需要模型准确地将预设锚框（anchor box）准确地回归至检测物体的标注框（bounding box），低比特量化后的模型可能难以处理这一回归任务；
  \item 检测模型为保持特征图（feature map）的空间信息，其输入尺寸较分类任务增大（一般检测模型输入图像短边尺寸为 $600\sim 800$ 像素）而占用更多 GPU 显存，导致训练时单 GPU 批量大小（batch size）缩小至 2 或 4，从而影响模型中部分正则化操作，例如批正则化（Batch Normalization~\citep{ioffe2015batch}，下文简称 BN）层的效率，使得本身就难以训练的量化网络更不稳定、难以收敛；
  \item 大部分运行量化模型的专有硬件，例如终端设备上嵌入的 FPGA 和 DSP 等，为保证硬件利用率和访存效率，并不包含浮点运算单元。这要求量化检测模型在训练后不包含任何浮点操作，而现有的大部分模型量化算法（……）为保证模型量化后准确度，会将模型的 BN 层等敏感部分数值精度保留为浮点。同时，一些模型量化方法对一般硬件部署并不友好，例如 codebook 量化（……）等。
\end{enumerate}

针对上述挑战，本章提出了一种适用于目标检测任务且对于一般硬件友好的低比特量化神经网络训练及部署方法，称为\emph{用于目标检测的全量化网络}（\emph{Fully Quantized Network for Object Detection}，下文简称 FQN）。FQN 可以在复杂的目标检测模型——例如 RetinaNet 和 Faster RCNN 上——将量化数值精度降低至 4 比特，并保持足够的准确度。FQN 使用对于一般硬件友好的线性量化，且通过 BN 折叠技术，使模型训练后不包含任何浮点操作。为解决 FQN 的训练收敛问题，本章详细分析了其在 MS COCO 数据集上的训练过程，指出其训练不稳定性的根源在于模型参数的通道间分布差异、模型激活量化的准确度不足以及小训练批量尺寸导致的 BN 统计量不稳定，并提出了相应的措施解决上述问题。

本章在 MS COCO 数据集上验证 FQN 的有效性，所用的检测算法包括一阶检测算法 RetinaNet 和二阶检测算法 Faster RCNN，所用的模型包括使用特征金字塔（Feature Pyramid Network，下文简称 FPN）的 ResNet-\{18, 34, 50\} 和 MobileNet-v2。FQN 在上述实验中均保持了较高准确度，例如使用 4-bit ResNet-18 的 RetinaNet 检测模型应用 FQN 训练后，其 mAP 相较全精度模型仅下降 $0.031$ 个百分点（4-bit $0.286$ mAP 相较于全精度 $0.317$ mAP），而之前被用于 TensorFlow Lite 中的 integer only 算法和 white paper 算法 mAP 下降分别为 $0.120$ 和 $0.091$，其相对准确度损失是 FQN 的 $3.87\times$ 和 $2.94\times$。
% ------------------------------------------------------------------------------
%    Motivation
% ------------------------------------------------------------------------------
\subsection{工作动机}
TODO
% ------------------------------------------------------------------------------
%    Contributions
% ------------------------------------------------------------------------------
\subsection{主要贡献}
TODO

% ==============================================================================
%  Method
% ==============================================================================
\section{目标检测模型的量化}
TODO
% ------------------------------------------------------------------------------
%    Quantize weights
% ------------------------------------------------------------------------------
\subsection{模型参数量化}
TODO
% ------------------------------------------------------------------------------
%    Quantize activations
% ------------------------------------------------------------------------------
\subsection{模型激活量化}
TODO
% ------------------------------------------------------------------------------
%    Misc
% ------------------------------------------------------------------------------
\subsection{量化算法细节}
TODO

% ==============================================================================
%  Deployment considerations
% ==============================================================================
\section{真实世界硬件部署的考量}
TODO

% ==============================================================================
%  Experiments
% ==============================================================================
\section{主要实验结果}
TODO

% ==============================================================================
%  Ablation study
% ==============================================================================
\section{对比实验及分析}
TODO

% ==============================================================================
%  Conclusion
% ==============================================================================
\section{结论}
TODO
