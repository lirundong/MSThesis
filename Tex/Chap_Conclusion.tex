\chapter{总结与展望}
智能终端设备正积极地影响着现代生活，而其有限的计算力和能耗资源使得学术界和工业界愈发迫切地探索轻量、高效、能够适用于复杂任务的算法模型。本文以目标检测任务作为切入点，探讨了将神经网络量化压缩技术应用至复杂任务模型的挑战，并从两个角度给出了解决方案：不同任务和模型在量化部署过程中会展现出其独有的困难，因此可以针对特定任务提出\emph{专用}的量化压缩算法；同时，量化神经网络的误差根源是统一的——其模型参数和激活量化后引入的数值误差，因此可以为使用量化神经网络的压缩加速方法提出\emph{通用}的训练算法框架。

本文第~\ref{chap::fqn} 章通过分析用于目标检测这一特定任务的量化神经网络模型在训练和部署过程中的困难，提出了专门适用于目标检测模型的量化方法 Fully Quantized Network for Object Detection (FQN)。FQN 通过对模型参数逐通道量化、使用基于分布分位点的激活标定方法、稳定化的 BN 折叠等方法，降低了目标检测模型在量化训练中的不稳定性，最终在 4-bit 数值精度下得到了接近全精度模型准确度的量化目标检测模型。

本文第~\ref{chap::gq_nets} 章通过相同输入下同一模型量化输出和全精度输出间的差异作为量化误差建模，端到端地考虑了神经网络参数和激活被量化后的误差影响，并据此提出了训练通用的、对量化部署友好的训练算法框架 Guided Quantization Networks (GQ-Nets)。GQ-Nets 可以在模型预训练阶段直接得到量化后几乎不损失准确度的神经网络模型，故不再需要额外的量化感知训练等流程。在不同的量化范式和量化数值精度下，GQ-Nets 可达到或超过先前最优方法的准确度。

量化神经网络仍然是一个充满着崭新挑战和机遇的研究领域。从神经网络的通用量化方法的角度，可能的未来工作方向包括：
\begin{enumerate}
  \item \textbf{更有效的计算资源分配}：神经网络模型不同部分对量化误差的敏感性不一致，因此在支持混合数值精度——例如，同时支持 FP16、INT8、INT4 算术操作——的部署平台上，为模型不同部分分配不同量化数值精度将会进一步提高量化神经网络的运行效率；
  \item \textbf{更高效的优化方法}：量化神经网络的训练过程仍然存在梯度不匹配导致的训练收敛问题，在复杂任务的极低比特量化场景下更为明显。为复杂模型和任务设计 2-bit 或二值化数值精度下的优化方法会极大地促进极低比特量化压缩技术在其他领域的普及。
\end{enumerate}

从用于特定任务的专用量化方法的角度，可能的工作方向包括：
\begin{enumerate}
  \item \textbf{用于自然语言处理、推荐系统等领域的模型量化技术}：不同于模型体积在 MB 量级的计算机视觉领域模型，部署在服务器端的自然语言处理、推荐系统等领域模型体积可以达 GB 量级。将模型量化技术应用到这些领域将会极大地减轻数据中心的计算和能耗负担；
  \item \textbf{使用 AutoML 技术自动化模型的量化训练及部署}：随着应用场景和部署平台的扩增，为每一任务单独分析并设计量化算法的开销将高至无法承受。将模型量化技术融入至 AutoML 系统中，将是未来神经网络模型高效训练和部署的主流方向。
\end{enumerate}
